{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7813480-ce22-4459-bd6b-055c7b086fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Downloading psycopg2-2.9.9-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
      "Downloading psycopg2-2.9.9-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.2 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.2 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 7.4 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.9\n"
     ]
    }
   ],
   "source": [
    "#!pip install requests\n",
    "#!pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a25c2e1-d425-4214-8458-1bc1bd514344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import tempfile\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, when,concat, lit,regexp_replace\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "from pyspark.sql.functions import concat_ws\n",
    "import json\n",
    "import psycopg2\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "### Define JDBC path\n",
    "jar_path = os.path.abspath(\"./postgresql-42.7.4.jar\")\n",
    "\n",
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#Create Spark session including JAR\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('pySparkSetup') \\\n",
    "    .config(\"spark.jars\", jar_path) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a68f0a-7d2e-4778-b0b3-2c0821cb3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB Connection\n",
    "url_db = \"jdbc:postgresql://localhost:5432/postgres\"  # Cambia la URL si tu DB tiene otro puerto o host\n",
    "properties = {\n",
    "    \"user\": \"postgres\",         # Coloca tu usuario de PostgreSQL\n",
    "    \"password\": \"postgres\",  # Coloca tu contrase√±a de PostgreSQL\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50c7ea7d-beae-460d-9a34-a972126afbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: You should change the values to the database connection psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4717e636-2ac9-42f1-886b-03709d8223e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_now_str 2024-09-06T09:47:13-0700\n",
      "last_days_str 2024-08-30T09:47:13-0700\n"
     ]
    }
   ],
   "source": [
    "#Check currently date\n",
    "timezone = pytz.timezone('US/Pacific')\n",
    "\n",
    "# datetime variables containing current date\n",
    "date_now = datetime.now(timezone)\n",
    "\n",
    "# Substract 7 days to fetch the last week\n",
    "last_days=(date_now - timedelta(days=7))\n",
    "\n",
    "date_now_str = date_now.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "last_days_str = last_days.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "print(\"date_now_str\", date_now_str)\n",
    "print(\"last_days_str\", last_days_str)\n",
    "\n",
    "#Now I can get the last 7 days in the api endpoint https://api.weather.gov/stations/station_id/observations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc66acd-b1c7-47c9-9de6-30cc7b94b93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://api.weather.gov/stations/0128W/observations?start=2024-08-30T09:47:13-0700&end=2024-09-06T09:47:13-0700\n"
     ]
    }
   ],
   "source": [
    "# Variables declaration, if I need change the statition ID or another params to the request \n",
    "\n",
    "#Here I can change for other value, if the solution is called in AWS GLUE for example or called it in State machine\n",
    "#The station_id will be in the arguments\n",
    "\n",
    "station_id= \"0128W\" #\"0112W\" \n",
    "\n",
    "\n",
    "# Build ulr with the parameters\n",
    "url_ep = f\"https://api.weather.gov/stations/{station_id}/observations?start={last_days_str}&end={date_now_str}\"\n",
    "\n",
    "\n",
    "print(\"URL:\", url_ep)\n",
    "\n",
    "# Fetch de data\n",
    "response = requests.get(url_ep)\n",
    "\n",
    "#If response == 200 it is OK\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    #Save the JSON in temporal file, I don't know the size of data so this way keep less memory in usage\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".json\", mode='w') as temp_file:\n",
    "        json.dump(data['features'], temp_file)\n",
    "        temp_filename = temp_file.name\n",
    "    # Read the json file\n",
    "    df = spark.read.json(temp_filename)\n",
    "else:\n",
    "    print(\"Error\", response.status_code)\n",
    "    print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "313406bf-523e-4d45-bb9c-8db24eff896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an UDF for get the name from other link properties.station with that I can go to the name,timeZone,coordinates of station.\n",
    "def get_station_info(station_url):\n",
    "    try:\n",
    "        # Fetch data,\n",
    "        response = requests.get(station_url)\n",
    "        # if response equal to 200 it is OK\n",
    "        if response.status_code == 200:\n",
    "            station_data = response.json()\n",
    "            \n",
    "            #Get the station name\n",
    "            station_name = station_data.get('properties', {}).get('name', \"Unknown\")\n",
    "            \n",
    "            #Get the station time_zone\n",
    "            time_zone = station_data.get('properties', {}).get('timeZone', \"Unknown\")\n",
    "            \n",
    "            #Get the station coordinates\n",
    "            coordinates = station_data.get('geometry', {}).get('coordinates', [\"Unknown\", \"Unknown\"])\n",
    "            \n",
    "            return (station_name, time_zone, coordinates[0], coordinates[1])  # Nombre, zona horaria, latitud, longitud    \n",
    "        else:\n",
    "            return (\"Unknown\", \"Unknown\", \"Unknown\", \"Unknown\")  # Default values\n",
    "    except Exception as e:\n",
    "        return (\"Unknown\", \"Unknown\", \"Unknown\", \"Unknown\")  # Exception default values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3e4ba4-b79a-40b9-8523-615697aea8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux=df #Copy the data frame to avoid loose the original information\n",
    "\n",
    "df_selected = df_aux.select(\n",
    "    col(\"id\"),\n",
    "    col(\"properties.timestamp\").alias(\"timestamp\"),\n",
    "    col(\"properties.temperature.value\").alias(\"temperature_value\"),\n",
    "    col(\"properties.temperature.unitCode\").alias(\"temperature_unit\"),\n",
    "    col(\"properties.windSpeed.value\").alias(\"wind_speed_value\"),\n",
    "    col(\"properties.windSpeed.unitCode\").alias(\"wind_speed_unit\"),\n",
    "    col(\"properties.relativeHumidity.value\").alias(\"humidity_value\"),\n",
    "    col(\"properties.relativeHumidity.unitCode\").alias(\"humidity_unit\"),\n",
    "    col(\"properties.station\").alias(\"station_url\")\n",
    ")\n",
    "\n",
    "get_station_info_udf = udf(get_station_info, ArrayType(StringType()))\n",
    "\n",
    "#Using the UDF\n",
    "df_selected = df_selected.withColumn(\"station_info\", get_station_info_udf(col(\"station_url\")))\n",
    "\n",
    "#Splitting each data column\n",
    "df_selected = df_selected.withColumn(\"station_name\", col(\"station_info\")[0])\n",
    "df_selected = df_selected.withColumn(\"time_zone\", col(\"station_info\")[1])\n",
    "df_selected = df_selected.withColumn(\"latitude\", col(\"station_info\")[2])\n",
    "df_selected = df_selected.withColumn(\"longitude\", col(\"station_info\")[3])\n",
    "df_selected = df_selected.withColumn(\"station_id\",lit(station_id))\n",
    "df_selected =  df_selected.withColumn(\"temperature_unit\",regexp_replace(col(\"temperature_unit\"), \"wmoUnit:\", \"\"))\n",
    "df_selected =  df_selected.withColumn(\"humidity_unit\",regexp_replace(col(\"humidity_unit\"), \"wmoUnit:\", \"\"))\n",
    "df_selected =  df_selected.withColumn(\"wind_speed_unit\",regexp_replace(col(\"wind_speed_unit\"), \"wmoUnit:\", \"\"))\n",
    "\n",
    "\n",
    "#Drop column 'station_info' \n",
    "df_selected = df_selected.drop(\"station_info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff6bbcbf-b5bb-43b5-b4f6-149c8ec9aa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created successfully.\n"
     ]
    }
   ],
   "source": [
    "#Create a cursor\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Verificar si la tabla existe\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT EXISTS (\n",
    "        SELECT 1\n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public' \n",
    "        AND table_name = 'weather_information'\n",
    "    );\n",
    "\"\"\")\n",
    "\n",
    "#Check if the table exists\n",
    "table_exists = cursor.fetchone()[0]\n",
    "\n",
    "\n",
    "if not table_exists:\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE public.weather_information (\n",
    "            station_id varchar NOT NULL,\n",
    "            station_name varchar NULL,\n",
    "            station_timezone varchar NULL,\n",
    "            latitude float8 NULL,\n",
    "            longitude float8 NULL,\n",
    "            observation_timestamp varchar NULL,\n",
    "            temperature varchar NULL,\n",
    "            temperature_unit varchar NULL,\n",
    "            wind_speed varchar NULL,\n",
    "            wind_speed_unit varchar NULL,\n",
    "            humidity varchar NULL,\n",
    "            humidity_unit varchar NULL,\n",
    "            createt_at timestamp(0) NULL DEFAULT now(),\n",
    "            station_url varchar NULL,\n",
    "            id varchar NULL\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"Table created successfully.\")\n",
    "else:\n",
    "    print(\"Table exists.\")\n",
    "\n",
    "# Cerrar la conexi√≥n\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a955b0-5967-4333-b85d-62ead224998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------------+---------+---------+---------------------+-----------+----------------+----------+---------------+---------------+-------------+--------------------+--------------------+\n",
      "|station_id|        station_name|station_timezone|longitude| latitude|observation_timestamp|temperature|temperature_unit|wind_speed|wind_speed_unit|       humidity|humidity_unit|         station_url|                  id|\n",
      "+----------+--------------------+----------------+---------+---------+---------------------+-----------+----------------+----------+---------------+---------------+-------------+--------------------+--------------------+\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T16:10:...|      33.72|            degC|     4.824|         km_h-1|63.420955014286|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T15:40:...|      33.44|            degC|     6.444|         km_h-1|67.820320112869|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T15:30:...|      32.89|            degC|       0.0|         km_h-1|67.514079342165|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T15:10:...|       32.5|            degC|     8.028|         km_h-1| 71.83889432732|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T15:00:...|       32.0|            degC|      3.24|         km_h-1|73.032862721079|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T14:50:...|      31.89|            degC|     4.824|         km_h-1|73.836573905473|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T14:40:...|      31.56|            degC|    11.268|         km_h-1|75.498390315651|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T14:30:...|      31.22|            degC|     6.444|         km_h-1| 76.74633557188|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T14:10:...|      30.67|            degC|      3.24|         km_h-1|79.520257229875|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T14:00:...|       30.5|            degC|     6.444|         km_h-1|80.771345495358|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T13:50:...|      29.83|            degC|      3.24|         km_h-1|82.759889317088|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T13:40:...|      29.44|            degC|      3.24|         km_h-1|84.093387350074|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T13:30:...|      29.11|            degC|     9.648|         km_h-1|84.456218561772|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T13:10:...|      28.28|            degC|     6.444|         km_h-1|87.269991454212|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T13:00:...|      27.78|            degC|     4.824|         km_h-1|88.058596722163|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T12:40:...|      27.06|            degC|      3.24|         km_h-1|90.228164545704|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T12:30:...|      26.67|            degC|     4.824|         km_h-1|91.065761195651|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T12:10:...|       26.0|            degC|      3.24|         km_h-1|92.284353041358|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T12:00:...|      25.72|            degC|      3.24|         km_h-1|92.601022689985|      percent|https://api.weath...|https://api.weath...|\n",
      "|     0128W|Ringling Museum o...|America/New_York| 27.38139|-82.55997| 2024-09-06T11:50:...|      25.44|            degC|      1.62|         km_h-1|92.697298546103|      percent|https://api.weath...|https://api.weath...|\n",
      "+----------+--------------------+----------------+---------+---------+---------------------+-----------+----------------+----------+---------------+---------------+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mapping each column to SQL table\n",
    "df_sql = df_selected.select(\n",
    "    col(\"station_id\"),\n",
    "    col(\"station_name\"),\n",
    "    col(\"time_zone\").alias(\"station_timezone\"),\n",
    "    when(col(\"longitude\") == \"Unknown\", None).otherwise(col(\"longitude\").cast(\"float\")).alias(\"longitude\"), \n",
    "    when(col(\"latitude\") == \"Unknown\", None).otherwise(col(\"latitude\").cast(\"float\")).alias(\"latitude\"), \n",
    "    col(\"timestamp\").alias(\"observation_timestamp\"),\n",
    "    col(\"temperature_value\").alias(\"temperature\"),\n",
    "    col(\"temperature_unit\"),\n",
    "    col(\"wind_speed_value\").alias(\"wind_speed\"),\n",
    "    col(\"wind_speed_unit\"),\n",
    "    col(\"humidity_value\").alias(\"humidity\"),\n",
    "    col(\"humidity_unit\"),\n",
    "    col(\"station_url\"),\n",
    "    col(\"id\")\n",
    ")\n",
    "\n",
    "#Query to get max  observation_timestamp in all table to ask Which information will be Insert or Not\n",
    "query = \"(SELECT MAX(observation_timestamp) as max_timestamp FROM public.weather_information WHERE station_id = '\"+station_id+\"' ) AS temp\"\n",
    "\n",
    "\n",
    "#Read query\n",
    "df_max_timestamp = spark.read.jdbc(url=url_db, table=query, properties=properties)\n",
    "\n",
    "\n",
    "max_timestamp = df_max_timestamp.collect()[0][\"max_timestamp\"]\n",
    "\n",
    "#Filter the data to Insert only the rows wich timestamp greater than the max timestamp in the table\n",
    "#If max timestamp does not exist will insert all data frame\n",
    "if max_timestamp is None:\n",
    "    df_filtered=df_sql\n",
    "else:\n",
    "    df_filtered = df_sql.filter(col(\"observation_timestamp\") > max_timestamp)\n",
    "\n",
    "# Mostrar el DataFrame filtrado\n",
    "df_filtered.show()\n",
    "\n",
    "#Write data frame in database\n",
    "df_filtered.write.jdbc(url=url_db, table=\"weather_information\", mode=\"append\", properties=properties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023d02b-5dc4-443b-9d53-14ffccad0955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
